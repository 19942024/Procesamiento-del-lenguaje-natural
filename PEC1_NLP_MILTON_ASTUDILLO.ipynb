{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0znDvip19Pc",
        "outputId": "4c3de02b-0a80-4e95-ac49-9846064c78f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CARGAMOS DATOS**"
      ],
      "metadata": {
        "id": "sKHJYBjiAsug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "import json\n",
        "\n",
        "# Ruta al archivo en tu Google Drive\n",
        "file_path = '/content/drive/My Drive/Appliances_5.json.gz'\n",
        "\n",
        "# Cargar el archivo JSON\n",
        "with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
        "    data = [json.loads(line) for line in f]\n",
        "\n",
        "# Convertir a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Mostrar las primeras filas del dataframe\n",
        "print(df.head())\n",
        "\n",
        "# Información del dataframe\n",
        "print(df.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVRlNqcD2PCv",
        "outputId": "bd8bd727-0f1d-436b-880d-6c9b34e173e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   overall  verified   reviewTime      reviewerID        asin  \\\n",
            "0      5.0      True  08 22, 2013  A34A1UP40713F8  B00009W3I4   \n",
            "1      5.0      True   02 8, 2016  A1AHW6I678O6F2  B00009W3PA   \n",
            "2      5.0      True   08 5, 2015   A8R48NKTGCJDQ  B00009W3PA   \n",
            "3      5.0      True  04 24, 2015   AR3OHHHW01A8E  B00009W3PA   \n",
            "4      5.0      True  03 21, 2015  A2CIEGHZ7L1WWR  B00009W3PA   \n",
            "\n",
            "                       style     reviewerName  \\\n",
            "0  {'Style:': ' Dryer Vent'}    James. Backus   \n",
            "1       {'Size:': ' 6-Foot'}           kevin.   \n",
            "2       {'Size:': ' 6-Foot'}        CDBrannom   \n",
            "3       {'Size:': ' 6-Foot'}  Calvin E Reames   \n",
            "4       {'Size:': ' 6-Foot'}   albert j. kong   \n",
            "\n",
            "                                          reviewText        summary  \\\n",
            "0  I like this as a vent as well as something tha...  Great product   \n",
            "1                                          good item     Five Stars   \n",
            "2                     Fit my new LG dryer perfectly.     Five Stars   \n",
            "3                     Good value for electric dryers   Perfect size   \n",
            "4                  Price and delivery was excellent.     Five Stars   \n",
            "\n",
            "   unixReviewTime vote image  \n",
            "0      1377129600  NaN   NaN  \n",
            "1      1454889600  NaN   NaN  \n",
            "2      1438732800  NaN   NaN  \n",
            "3      1429833600  NaN   NaN  \n",
            "4      1426896000  NaN   NaN  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2277 entries, 0 to 2276\n",
            "Data columns (total 12 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   overall         2277 non-null   float64\n",
            " 1   verified        2277 non-null   bool   \n",
            " 2   reviewTime      2277 non-null   object \n",
            " 3   reviewerID      2277 non-null   object \n",
            " 4   asin            2277 non-null   object \n",
            " 5   style           38 non-null     object \n",
            " 6   reviewerName    2277 non-null   object \n",
            " 7   reviewText      2277 non-null   object \n",
            " 8   summary         2277 non-null   object \n",
            " 9   unixReviewTime  2277 non-null   int64  \n",
            " 10  vote            2074 non-null   object \n",
            " 11  image           828 non-null    object \n",
            "dtypes: bool(1), float64(1), int64(1), object(9)\n",
            "memory usage: 198.0+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LIMPIEZA Y PREPARACION DE DATOS**"
      ],
      "metadata": {
        "id": "Xtwlpe27cZpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Eliminar filas con valores nulos en `reviewText` y `overall`\n",
        "df_clean = df.dropna(subset=['reviewText', 'overall'])\n",
        "\n",
        "# Convertir la columna 'overall' a tipo numérico\n",
        "df_clean['overall'] = pd.to_numeric(df_clean['overall'], errors='coerce')\n",
        "\n",
        "# Eliminar filas con valores negativos en `overall`\n",
        "df_clean = df_clean[df_clean['overall'] >= 0]\n",
        "\n",
        "# Convertir las puntuaciones `overall` a una clasificación binaria\n",
        "df_clean['label'] = df_clean['overall'].apply(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "# Función para limpiar el texto\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convertir a minúsculas\n",
        "    text = re.sub(r'\\d+', '', text)  # Eliminar números\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # Eliminar puntuación\n",
        "    text = text.strip()  # Eliminar espacios en blanco al inicio y al final\n",
        "    return text\n",
        "\n",
        "# Aplicar limpieza de texto\n",
        "df_clean['cleaned_reviewText'] = df_clean['reviewText'].apply(clean_text)\n",
        "\n",
        "# División de los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_clean['cleaned_reviewText'], df_clean['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "print(X_train.head())\n",
        "print(y_train.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFUOim6TZy_L",
        "outputId": "38b2f404-2435-4dcd-9e28-991081c42c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2008    this review is for gardus rle linteater piece ...\n",
            "2142    first thing first it works the kit is great in...\n",
            "2015    i bought this last october and finally got aro...\n",
            "8       luved it for the few months it worked  great l...\n",
            "1530    at first this contraption was a little confusi...\n",
            "Name: cleaned_reviewText, dtype: object\n",
            "2008    1\n",
            "2142    0\n",
            "2015    1\n",
            "8       0\n",
            "1530    0\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clasificador en base a heurísticas (Regexp y lexicones)**"
      ],
      "metadata": {
        "id": "UVX18ckuArG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#definimos un lexicon simple\n",
        "positive_words = set(['good', 'great', 'excellent', 'amazing', 'fantastic', 'love'])\n",
        "negative_words = set(['bad', 'terrible', 'awful', 'worst', 'poor', 'hate'])\n",
        "\n",
        "def heuristic_classifier(text):\n",
        "    pos_count = sum([1 for word in text.split() if word in positive_words])\n",
        "    neg_count = sum([1 for word in text.split() if word in negative_words])\n",
        "    return 1 if pos_count > neg_count else 0\n",
        "\n",
        "# Aplicar el clasificador heurístico al conjunto de prueba\n",
        "heuristic_predictions = X_test.apply(heuristic_classifier)\n",
        "\n",
        "# Evaluación del clasificador heurístico\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "heuristic_accuracy = accuracy_score(y_test, heuristic_predictions)\n",
        "heuristic_accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LtjCbgMd-1R",
        "outputId": "315dca1e-d6ea-4bce-ba4f-2b38ae486f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.618421052631579"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Representación del Texto mediante BoW y Clasificación**"
      ],
      "metadata": {
        "id": "kW_AsYcbfoxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Representación BoW\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "X_test_bow = vectorizer.transform(X_test)\n",
        "\n",
        "# Clasificador Naive Bayes\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_bow, y_train)\n",
        "nb_predictions = nb_classifier.predict(X_test_bow)\n",
        "\n",
        "# Evaluación del clasificador Naive Bayes\n",
        "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
        "\n",
        "# Clasificador de Regresión Logística\n",
        "lr_classifier = LogisticRegression(max_iter=1000)\n",
        "lr_classifier.fit(X_train_bow, y_train)\n",
        "lr_predictions = lr_classifier.predict(X_test_bow)\n",
        "\n",
        "# Evaluación del clasificador de Regresión Logística\n",
        "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
        "\n",
        "nb_accuracy, lr_accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjd4eRcKf1hA",
        "outputId": "5f1244ba-06e6-4924-97dd-0d7e32101e10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9846491228070176, 0.9956140350877193)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "vemos que el clasificador de Regresion logistica nos da un mejor resultado, aunque con muy poca diferencia."
      ],
      "metadata": {
        "id": "h8ed_hPOgGQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Empleo de Word Embeddings como representación del texto y clasificador**"
      ],
      "metadata": {
        "id": "DNMTTCKCnFnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Crear embeddings Word2Vec sobre el propio corpus\n",
        "sentences = [text.split() for text in X_train]\n",
        "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=2, workers=4)\n",
        "w2v_model.train(sentences, total_examples=len(sentences), epochs=10)\n",
        "\n",
        "# Función para obtener los embeddings de Word2Vec\n",
        "def get_w2v_embeddings(text):\n",
        "    words = text.split()\n",
        "    embedding = np.mean([w2v_model.wv[word] for word in words if word in w2v_model.wv] or [np.zeros(100)], axis=0)\n",
        "    return embedding\n",
        "\n",
        "# Convertir los textos a sus embeddings\n",
        "X_train_w2v = np.array([get_w2v_embeddings(text) for text in X_train])\n",
        "X_test_w2v = np.array([get_w2v_embeddings(text) for text in X_test])\n",
        "\n",
        "# Clasificador de Regresión Logística\n",
        "lr_w2v_classifier = LogisticRegression(max_iter=1000)\n",
        "lr_w2v_classifier.fit(X_train_w2v, y_train)\n",
        "lr_w2v_predictions = lr_w2v_classifier.predict(X_test_w2v)\n",
        "\n",
        "# Evaluación del clasificador de Regresión Logística con Word Embeddings\n",
        "lr_w2v_accuracy = accuracy_score(y_test, lr_w2v_predictions)\n",
        "print(f\"Accuracy of Logistic Regression with Word Embeddings: {lr_w2v_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z-0qo-XmVcB",
        "outputId": "014791cf-9ebf-4431-969c-b0a5a3655edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Logistic Regression with Word Embeddings: 0.9956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clasificador con WE y una arquitectura de DL.**"
      ],
      "metadata": {
        "id": "Pia1taWqqSjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Tokenización y padding\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Definir la longitud máxima de las secuencias\n",
        "max_len = max(len(seq) for seq in X_train_seq)\n",
        "\n",
        "# Aplicar padding\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "\n",
        "# Crear una matriz de embeddings\n",
        "word_index = tokenizer.word_index\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, 100))\n",
        "for word, i in word_index.items():\n",
        "    if word in w2v_model.wv:\n",
        "        embedding_matrix[i] = w2v_model.wv[word]\n",
        "\n",
        "# Construir el modelo LSTM\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(word_index) + 1, output_dim=100, weights=[embedding_matrix], input_length=max_len, trainable=False))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "history = model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_data=(X_test_pad, y_test), verbose=2)\n",
        "\n",
        "# Evaluación del modelo\n",
        "dl_accuracy = model.evaluate(X_test_pad, y_test, verbose=0)[1]\n",
        "print(f\"Accuracy of LSTM with Word Embeddings: {dl_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OURDZk9WonB5",
        "outputId": "fe65fe79-b4e3-4cb8-ce8c-e7e1b8316b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "29/29 - 50s - loss: 0.2193 - accuracy: 0.9379 - val_loss: 0.0639 - val_accuracy: 0.9868 - 50s/epoch - 2s/step\n",
            "Epoch 2/5\n",
            "29/29 - 44s - loss: 0.0572 - accuracy: 0.9857 - val_loss: 0.0395 - val_accuracy: 0.9868 - 44s/epoch - 2s/step\n",
            "Epoch 3/5\n",
            "29/29 - 46s - loss: 0.0402 - accuracy: 0.9879 - val_loss: 0.0318 - val_accuracy: 0.9868 - 46s/epoch - 2s/step\n",
            "Epoch 4/5\n",
            "29/29 - 47s - loss: 0.0316 - accuracy: 0.9890 - val_loss: 0.0216 - val_accuracy: 0.9912 - 47s/epoch - 2s/step\n",
            "Epoch 5/5\n",
            "29/29 - 45s - loss: 0.0253 - accuracy: 0.9918 - val_loss: 0.0165 - val_accuracy: 0.9934 - 45s/epoch - 2s/step\n",
            "Accuracy of LSTM with Word Embeddings: 0.9934210777282715\n"
          ]
        }
      ]
    }
  ]
}