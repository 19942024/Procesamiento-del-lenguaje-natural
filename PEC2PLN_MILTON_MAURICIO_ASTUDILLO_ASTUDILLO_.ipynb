{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "94332fb4",
      "metadata": {
        "id": "94332fb4"
      },
      "source": [
        "# Procesamiento del Lenguaje Natural\n",
        "# Prueba de Evaluación Continua 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c67cec",
      "metadata": {
        "id": "e8c67cec"
      },
      "source": [
        "**OBJETIVO 1**\n",
        "\n",
        "Extracción de información en forma de palabras clave y entidades relevantes (Named Entities) con el objetivo de etiquetar los documentos de nuestro corpus."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b524612d",
      "metadata": {
        "id": "b524612d"
      },
      "source": [
        "**Instalamos las bibliotecas necesarias**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61558b09",
      "metadata": {
        "id": "61558b09",
        "outputId": "e21e40c9-14f3-433a-ada7-78a16ace75af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: nltk in c:\\anaconda\\lib\\site-packages (3.8.1)\n",
            "Collecting spacy\n",
            "  Obtaining dependency information for spacy from https://files.pythonhosted.org/packages/39/e1/08681583569f435347ced0535b27c073fcc9a927d9b4293c963092f2d01c/spacy-3.7.5-cp311-cp311-win_amd64.whl.metadata\n",
            "  Downloading spacy-3.7.5-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (1.3.2)\n",
            "Requirement already satisfied: pandas in c:\\anaconda\\lib\\site-packages (2.0.3)\n",
            "Requirement already satisfied: click in c:\\anaconda\\lib\\site-packages (from nltk) (8.0.4)\n",
            "Requirement already satisfied: joblib in c:\\anaconda\\lib\\site-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\anaconda\\lib\\site-packages (from nltk) (2022.7.9)\n",
            "Requirement already satisfied: tqdm in c:\\anaconda\\lib\\site-packages (from nltk) (4.65.0)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
            "  Obtaining dependency information for spacy-legacy<3.1.0,>=3.0.11 from https://files.pythonhosted.org/packages/c3/55/12e842c70ff8828e34e543a2c7176dac4da006ca6901c9e8b43efab8bc6b/spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata\n",
            "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
            "  Obtaining dependency information for spacy-loggers<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/33/78/d1a1a026ef3af911159398c939b1509d5c36fe524c7b644f34a5146c4e16/spacy_loggers-1.0.5-py3-none-any.whl.metadata\n",
            "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
            "  Obtaining dependency information for murmurhash<1.1.0,>=0.28.0 from https://files.pythonhosted.org/packages/71/46/af01a20ec368bd9cb49a1d2df15e3eca113bbf6952cc1f2a47f1c6801a7f/murmurhash-1.0.10-cp311-cp311-win_amd64.whl.metadata\n",
            "  Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
            "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
            "  Obtaining dependency information for cymem<2.1.0,>=2.0.2 from https://files.pythonhosted.org/packages/c1/c3/dd044e6f62a3d317c461f6f0c153c6573ed13025752d779e514000c15dd2/cymem-2.0.8-cp311-cp311-win_amd64.whl.metadata\n",
            "  Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
            "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
            "  Obtaining dependency information for preshed<3.1.0,>=3.0.2 from https://files.pythonhosted.org/packages/e4/fc/78cdbdb79f5d6d45949e72c32445d6c060977ad50a1dcfc0392622165f7c/preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata\n",
            "  Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
            "Collecting thinc<8.3.0,>=8.2.2 (from spacy)\n",
            "  Obtaining dependency information for thinc<8.3.0,>=8.2.2 from https://files.pythonhosted.org/packages/46/a9/34b82ee16f4b5da2ced75a068ea0ab616e178269af17d6555266a44dfcc4/thinc-8.2.4-cp311-cp311-win_amd64.whl.metadata\n",
            "  Downloading thinc-8.2.4-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
            "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
            "  Obtaining dependency information for wasabi<1.2.0,>=0.9.1 from https://files.pythonhosted.org/packages/06/7c/34330a89da55610daa5f245ddce5aab81244321101614751e7537f125133/wasabi-1.1.3-py3-none-any.whl.metadata\n",
            "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
            "  Obtaining dependency information for srsly<3.0.0,>=2.4.3 from https://files.pythonhosted.org/packages/eb/f5/e3f29993f673d91623df6413ba64e815dd2676fd7932cbc5e7347402ddae/srsly-2.4.8-cp311-cp311-win_amd64.whl.metadata\n",
            "  Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
            "  Obtaining dependency information for catalogue<2.1.0,>=2.0.6 from https://files.pythonhosted.org/packages/9e/96/d32b941a501ab566a16358d68b6eb4e4acc373fab3c3c4d7d9e649f7b4bb/catalogue-2.0.10-py3-none-any.whl.metadata\n",
            "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
            "  Obtaining dependency information for weasel<0.5.0,>=0.1.0 from https://files.pythonhosted.org/packages/2a/87/abd57374044e1f627f0a905ac33c1a7daab35a3a815abfea4e1bafd3fdb1/weasel-0.4.1-py3-none-any.whl.metadata\n",
            "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
            "  Obtaining dependency information for typer<1.0.0,>=0.3.0 from https://files.pythonhosted.org/packages/20/b5/11cf2e34fbb11b937e006286ab5b8cfd334fde1c8fa4dd7f491226931180/typer-0.12.3-py3-none-any.whl.metadata\n",
            "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\anaconda\\lib\\site-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\anaconda\\lib\\site-packages (from spacy) (1.10.8)\n",
            "Requirement already satisfied: jinja2 in c:\\anaconda\\lib\\site-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in c:\\anaconda\\lib\\site-packages (from spacy) (68.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\lib\\site-packages (from spacy) (23.1)\n",
            "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
            "  Obtaining dependency information for langcodes<4.0.0,>=3.2.0 from https://files.pythonhosted.org/packages/58/70/4058ab0ebb082b18d06888e711baed7f33354a5e0b363bb627586d8c323a/langcodes-3.4.0-py3-none-any.whl.metadata\n",
            "  Downloading langcodes-3.4.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: numpy>=1.19.0 in c:\\anaconda\\lib\\site-packages (from spacy) (1.24.3)\n",
            "Requirement already satisfied: scipy>=1.5.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\anaconda\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda\\lib\\site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
            "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
            "  Obtaining dependency information for language-data>=1.2 from https://files.pythonhosted.org/packages/12/5f/139464da89c49afcc8bb97ebad48818a535220ce01b1f24c61fb80dbe4d0/language_data-1.2.0-py3-none-any.whl.metadata\n",
            "  Downloading language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
            "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy)\n",
            "  Obtaining dependency information for blis<0.8.0,>=0.7.8 from https://files.pythonhosted.org/packages/2f/09/da0592c74560cc33396504698122f7a56747c82a5e072ca7d2c3397898e1/blis-0.7.11-cp311-cp311-win_amd64.whl.metadata\n",
            "  Downloading blis-0.7.11-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
            "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy)\n",
            "  Obtaining dependency information for confection<1.0.0,>=0.0.1 from https://files.pythonhosted.org/packages/0c/00/3106b1854b45bd0474ced037dfe6b73b90fe68a68968cef47c23de3d43d2/confection-0.1.5-py3-none-any.whl.metadata\n",
            "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
            "  Obtaining dependency information for shellingham>=1.3.0 from https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl.metadata\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
            "  Obtaining dependency information for rich>=10.11.0 from https://files.pythonhosted.org/packages/87/67/a37f6214d0e9fe57f6ae54b2956d550ca8365857f42a1ce0392bb21d9410/rich-13.7.1-py3-none-any.whl.metadata\n",
            "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
            "  Obtaining dependency information for cloudpathlib<1.0.0,>=0.7.0 from https://files.pythonhosted.org/packages/bc/ba/d8f2c0151585519759135550574385dd7a223abbc6b6c06dab7ada565773/cloudpathlib-0.18.1-py3-none-any.whl.metadata\n",
            "  Downloading cloudpathlib-0.18.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\anaconda\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
            "Collecting marisa-trie>=0.7.7 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
            "  Obtaining dependency information for marisa-trie>=0.7.7 from https://files.pythonhosted.org/packages/61/28/b93cd14cd422be8fc091bd454dd48edbf0c2333111183db38c8e5a13e468/marisa_trie-1.2.0-cp311-cp311-win_amd64.whl.metadata\n",
            "  Downloading marisa_trie-1.2.0-cp311-cp311-win_amd64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\anaconda\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\anaconda\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\anaconda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
            "Downloading spacy-3.7.5-cp311-cp311-win_amd64.whl (12.1 MB)\n",
            "   ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.2/12.1 MB 11.5 MB/s eta 0:00:02\n",
            "   - -------------------------------------- 0.3/12.1 MB 2.5 MB/s eta 0:00:05\n",
            "   - -------------------------------------- 0.4/12.1 MB 2.0 MB/s eta 0:00:06\n",
            "   - -------------------------------------- 0.6/12.1 MB 2.8 MB/s eta 0:00:05\n",
            "   --- ------------------------------------ 1.2/12.1 MB 3.7 MB/s eta 0:00:03\n",
            "   ---- ----------------------------------- 1.5/12.1 MB 4.0 MB/s eta 0:00:03\n",
            "   ---- ----------------------------------- 1.5/12.1 MB 4.0 MB/s eta 0:00:03\n",
            "   ---- ----------------------------------- 1.5/12.1 MB 4.0 MB/s eta 0:00:03\n",
            "   -------- ------------------------------- 2.6/12.1 MB 4.4 MB/s eta 0:00:03\n",
            "   -------------- ------------------------- 4.5/12.1 MB 6.3 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 5.0/12.1 MB 6.5 MB/s eta 0:00:02\n",
            "   --------------------- ------------------ 6.4/12.1 MB 7.0 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 7.0/12.1 MB 7.2 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 7.4/12.1 MB 7.1 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 8.0/12.1 MB 7.3 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 8.6/12.1 MB 7.4 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 9.2/12.1 MB 7.4 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 9.9/12.1 MB 7.6 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 10.4/12.1 MB 8.0 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 11.3/12.1 MB 8.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.9/12.1 MB 10.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.1/12.1 MB 10.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 12.1/12.1 MB 9.5 MB/s eta 0:00:00\n",
            "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
            "Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl (39 kB)\n",
            "Downloading langcodes-3.4.0-py3-none-any.whl (182 kB)\n",
            "   ---------------------------------------- 0.0/182.0 kB ? eta -:--:--\n",
            "   --------------------------------------- 182.0/182.0 kB 10.7 MB/s eta 0:00:00\n",
            "Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl (25 kB)\n",
            "Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
            "   ---------------------------------------- 0.0/122.3 kB ? eta -:--:--\n",
            "   ---------------------------------------- 122.3/122.3 kB 3.5 MB/s eta 0:00:00\n",
            "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
            "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
            "Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl (479 kB)\n",
            "   ---------------------------------------- 0.0/479.7 kB ? eta -:--:--\n",
            "   --------------------------------------- 479.7/479.7 kB 31.3 MB/s eta 0:00:00\n",
            "Downloading thinc-8.2.4-cp311-cp311-win_amd64.whl (1.5 MB)\n",
            "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
            "   ---------------------------------------  1.5/1.5 MB 47.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.5/1.5 MB 23.3 MB/s eta 0:00:00\n",
            "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "   ---------------------------------------- 0.0/47.2 kB ? eta -:--:--\n",
            "   ---------------------------------------- 47.2/47.2 kB 2.5 MB/s eta 0:00:00\n",
            "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
            "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
            "   ---------------------------------------- 0.0/50.3 kB ? eta -:--:--\n",
            "   -------------------------------- ------- 41.0/50.3 kB ? eta -:--:--\n",
            "   ---------------------------------------- 50.3/50.3 kB 367.2 kB/s eta 0:00:00\n",
            "Downloading blis-0.7.11-cp311-cp311-win_amd64.whl (6.6 MB)\n",
            "   ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
            "   ----------- ---------------------------- 2.0/6.6 MB 20.9 MB/s eta 0:00:01\n",
            "   -------------- ------------------------- 2.5/6.6 MB 15.7 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 3.2/6.6 MB 13.7 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 4.1/6.6 MB 12.4 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 5.0/6.6 MB 11.9 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 5.7/6.6 MB 11.4 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 6.3/6.6 MB 11.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.6/6.6 MB 11.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.6/6.6 MB 11.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.6/6.6 MB 11.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.6/6.6 MB 11.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 6.6/6.6 MB 7.4 MB/s eta 0:00:00\n",
            "Downloading cloudpathlib-0.18.1-py3-none-any.whl (47 kB)\n",
            "   ---------------------------------------- 0.0/47.3 kB ? eta -:--:--\n",
            "   ---------------------------------------- 47.3/47.3 kB ? eta 0:00:00\n",
            "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
            "Downloading language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
            "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
            "   ---------------- ----------------------- 2.2/5.4 MB 46.2 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 3.3/5.4 MB 19.3 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 4.2/5.4 MB 16.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  5.4/5.4 MB 13.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 5.4/5.4 MB 12.3 MB/s eta 0:00:00\n",
            "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
            "   ---------------------------------------- 0.0/240.7 kB ? eta -:--:--\n",
            "   --------------------------------------- 240.7/240.7 kB 14.4 MB/s eta 0:00:00\n",
            "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading marisa_trie-1.2.0-cp311-cp311-win_amd64.whl (152 kB)\n",
            "   ---------------------------------------- 0.0/152.6 kB ? eta -:--:--\n",
            "   ---------------------------------------- 152.6/152.6 kB ? eta 0:00:00\n",
            "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, shellingham, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, rich, preshed, language-data, typer, langcodes, confection, weasel, thinc, spacy\n",
            "Successfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.18.1 confection-0.1.5 cymem-2.0.8 langcodes-3.4.0 language-data-1.2.0 marisa-trie-1.2.0 murmurhash-1.0.10 preshed-3.0.9 rich-13.7.1 shellingham-1.5.4 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.4 typer-0.12.3 wasabi-1.1.3 weasel-0.4.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: The script typer.exe is installed in 'C:\\Users\\PC\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The script weasel.exe is installed in 'C:\\Users\\PC\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The script spacy.exe is installed in 'C:\\Users\\PC\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.1/12.8 MB 2.2 MB/s eta 0:00:06\n",
            "      --------------------------------------- 0.2/12.8 MB 1.8 MB/s eta 0:00:07\n",
            "      --------------------------------------- 0.3/12.8 MB 1.7 MB/s eta 0:00:08\n",
            "     - -------------------------------------- 0.4/12.8 MB 1.9 MB/s eta 0:00:07\n",
            "     - -------------------------------------- 0.6/12.8 MB 2.3 MB/s eta 0:00:06\n",
            "     --- ------------------------------------ 1.1/12.8 MB 3.3 MB/s eta 0:00:04\n",
            "     ---- ----------------------------------- 1.5/12.8 MB 3.9 MB/s eta 0:00:03\n",
            "     ---- ----------------------------------- 1.5/12.8 MB 3.9 MB/s eta 0:00:03\n",
            "     ---- ----------------------------------- 1.5/12.8 MB 3.9 MB/s eta 0:00:03\n",
            "     -------- ------------------------------- 2.7/12.8 MB 4.5 MB/s eta 0:00:03\n",
            "     ---------------- ----------------------- 5.2/12.8 MB 7.4 MB/s eta 0:00:02\n",
            "     ---------------- ----------------------- 5.2/12.8 MB 7.4 MB/s eta 0:00:02\n",
            "     ------------------- -------------------- 6.1/12.8 MB 7.4 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 7.4/12.8 MB 8.3 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 7.4/12.8 MB 8.3 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 7.4/12.8 MB 8.3 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 7.4/12.8 MB 8.3 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 7.4/12.8 MB 8.3 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 7.4/12.8 MB 8.3 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 7.4/12.8 MB 8.3 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 7.4/12.8 MB 8.3 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 7.4/12.8 MB 8.3 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 7.4/12.8 MB 8.3 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 7.4/12.8 MB 8.3 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 7.4/12.8 MB 8.3 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 7.4/12.8 MB 8.3 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 7.4/12.8 MB 8.3 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 7.4/12.8 MB 8.3 MB/s eta 0:00:01\n",
            "     ------------------------------ --------- 9.9/12.8 MB 5.9 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 11.5/12.8 MB 7.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------  12.8/12.8 MB 8.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------  12.8/12.8 MB 8.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------  12.8/12.8 MB 8.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------  12.8/12.8 MB 8.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------  12.8/12.8 MB 8.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------  12.8/12.8 MB 8.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------  12.8/12.8 MB 8.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------  12.8/12.8 MB 8.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 12.8/12.8 MB 5.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\anaconda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\anaconda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\anaconda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.8)\n",
            "Requirement already satisfied: jinja2 in c:\\anaconda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
            "Requirement already satisfied: setuptools in c:\\anaconda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in c:\\anaconda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\n",
            "Requirement already satisfied: language-data>=1.2 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\anaconda\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\anaconda\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\anaconda\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\anaconda\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\anaconda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.0)\n",
            "Installing collected packages: en-core-web-sm\n",
            "Successfully installed en-core-web-sm-3.7.1\n",
            "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk spacy scikit-learn pandas\n",
        "!python -m spacy download en_core_web_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec5fc4d8",
      "metadata": {
        "id": "ec5fc4d8",
        "outputId": "68ef8a20-2bbf-452f-89a7-060bb15c0ff8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id   ProductId          UserId                      ProfileName  \\\n",
              "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
              "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
              "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
              "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
              "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
              "\n",
              "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
              "0                     1                       1      5  1303862400   \n",
              "1                     0                       0      1  1346976000   \n",
              "2                     1                       1      4  1219017600   \n",
              "3                     3                       3      2  1307923200   \n",
              "4                     0                       0      5  1350777600   \n",
              "\n",
              "                 Summary                                               Text  \n",
              "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
              "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
              "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
              "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
              "4            Great taffy  Great taffy at a great price.  There was a wid...  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "# Cargar el archivo CSV\n",
        "df = pd.read_csv('Reviews.csv')\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe6acea0",
      "metadata": {
        "id": "fe6acea0"
      },
      "source": [
        "**Cargamos el corpus escogido \"Amazon Fine Food Reviews\" tomado desde https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews/data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c821f3e7",
      "metadata": {
        "id": "c821f3e7",
        "outputId": "620f76f7-0869-4bbd-95f8-78f951c0dd8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Id   ProductId          UserId                      ProfileName  \\\n",
            "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
            "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
            "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
            "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
            "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
            "\n",
            "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
            "0                     1                       1      5  1303862400   \n",
            "1                     0                       0      1  1346976000   \n",
            "2                     1                       1      4  1219017600   \n",
            "3                     3                       3      2  1307923200   \n",
            "4                     0                       0      5  1350777600   \n",
            "\n",
            "                 Summary                                               Text  \n",
            "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
            "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
            "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
            "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
            "4            Great taffy  Great taffy at a great price.  There was a wid...  \n",
            "Tamaño del corpus: 568454\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar el archivo CSV\n",
        "df = pd.read_csv('Reviews.csv')\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Descripción del corpus\n",
        "corpus_size = len(df)\n",
        "print(f\"Tamaño del corpus: {corpus_size}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cadb77b",
      "metadata": {
        "id": "8cadb77b"
      },
      "source": [
        "**Limpieza y preparación de los datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9762b2e9",
      "metadata": {
        "id": "9762b2e9",
        "outputId": "2c06d011-a722-4cee-b89b-e705932233ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                     Text  \\\n",
            "165256  Having tried a couple of other brands of glute...   \n",
            "231465  My cat loves these treats. If ever I can't fin...   \n",
            "427827  A little less than I expected.  It tends to ha...   \n",
            "433954  First there was Frosted Mini-Wheats, in origin...   \n",
            "70260   and I want to congratulate the graphic artist ...   \n",
            "\n",
            "                                             Cleaned_Text  \n",
            "165256  having try couple brand gluten free sandwich c...  \n",
            "231465  cat love treat find house pop bolt hide come t...  \n",
            "427827  little expect   tend muddy taste expect say fa...  \n",
            "433954  frosted mini wheat original size frosted mini ...  \n",
            "70260   want congratulate graphic artist put entire pr...  \n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.tokens import Token\n",
        "\n",
        "# Cargar el modelo de spaCy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Función de preprocesamiento\n",
        "def preprocess_text(text):\n",
        "    # Normalización: convertir a minúsculas\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenización y análisis con spaCy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Eliminación de stop words y puntuación\n",
        "    tokens = [token for token in doc if token.text not in STOP_WORDS and not token.is_punct]\n",
        "\n",
        "    # Lematización\n",
        "    lemmatized_tokens = [token.lemma_ for token in tokens]\n",
        "\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "# Aplicar la función de preprocesamiento a la columna 'Text'\n",
        "df_sample['Cleaned_Text'] = df_sample['Text'].apply(preprocess_text)\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame con el texto preprocesado\n",
        "print(df_sample[['Text', 'Cleaned_Text']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25a0cc90",
      "metadata": {
        "id": "25a0cc90"
      },
      "source": [
        "**Extracción de palabras clave (KPE) y PoS tagging con librerías pre-entrenadas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c27c42f",
      "metadata": {
        "id": "1c27c42f",
        "outputId": "b1e276f7-8941-45b6-cb1b-0b55b3e79f0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                             Cleaned_Text  \\\n",
            "165256  having try couple brand gluten free sandwich c...   \n",
            "231465  cat love treat find house pop bolt hide come t...   \n",
            "427827  little expect   tend muddy taste expect say fa...   \n",
            "433954  frosted mini wheat original size frosted mini ...   \n",
            "70260   want congratulate graphic artist put entire pr...   \n",
            "\n",
            "                                        Keywords_Entities  \n",
            "165256  ([couple, brand, free, cookie, good, bunch, cr...  \n",
            "231465  ([treat, house, pop, bolt, hide, crunchy, trea...  \n",
            "427827    ([little, muddy, taste, favorite, company], [])  \n",
            "433954  ([mini, wheat, original, size, mini, wheat, bi...  \n",
            "70260   ([graphic, artist, entire, product, small, box...  \n"
          ]
        }
      ],
      "source": [
        "# Función para extraer palabras clave y entidades nombradas del texto preprocesado\n",
        "def extract_keywords_entities(text):\n",
        "    doc = nlp(text)\n",
        "    keywords = [token.text for token in doc if token.pos_ in ['NOUN', 'ADJ']]\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return keywords, entities\n",
        "\n",
        "# Aplicar la función a la columna 'Cleaned_Text'\n",
        "df_sample['Keywords_Entities'] = df_sample['Cleaned_Text'].apply(extract_keywords_entities)\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(df_sample[['Cleaned_Text', 'Keywords_Entities']].head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0e68008",
      "metadata": {
        "id": "f0e68008"
      },
      "source": [
        "**Reconocimiento de entidades relevantes (NER) por medio de heurísticas, regexp, etiquetas PoS, lexicones, etc. En este caso nos enfocamos en los atributos de los productos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebd84bdd",
      "metadata": {
        "id": "ebd84bdd",
        "outputId": "3508967d-dd9e-48b6-e35b-d38d6e0a7e06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                             Cleaned_Text  \\\n",
            "165256  having try couple brand gluten free sandwich c...   \n",
            "231465  cat love treat find house pop bolt hide come t...   \n",
            "427827  little expect   tend muddy taste expect say fa...   \n",
            "433954  frosted mini wheat original size frosted mini ...   \n",
            "70260   want congratulate graphic artist put entire pr...   \n",
            "\n",
            "           Product_Attributes  \n",
            "165256       [taste, texture]  \n",
            "231465               [flavor]  \n",
            "427827                [taste]  \n",
            "433954  [flavor, size, taste]  \n",
            "70260                 [taste]  \n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Lista de posibles atributos de productos\n",
        "attributes = ['taste', 'price', 'quality', 'packaging', 'flavor', 'texture', 'smell', 'appearance', 'size', 'value']\n",
        "\n",
        "# Función para encontrar posibles atributos de productos utilizando heurísticas y regexp\n",
        "def find_product_attributes(text):\n",
        "    doc = nlp(text)\n",
        "    attributes_found = []\n",
        "\n",
        "    # Heurística: Buscar patrones comunes en los atributos de productos\n",
        "    pattern = re.compile(r'\\b(?:' + '|'.join(attributes) + r')\\b', re.IGNORECASE)\n",
        "\n",
        "    for sent in doc.sents:\n",
        "        if pattern.search(sent.text):\n",
        "            # Incluir tokens etiquetados como sustantivos y adjetivos relevantes\n",
        "            for token in sent:\n",
        "                if token.lemma_ in attributes:\n",
        "                    attributes_found.append(token.text.strip())\n",
        "    return list(set(attributes_found))  # Eliminar duplicados\n",
        "\n",
        "# Aplicar la función a la columna 'Cleaned_Text'\n",
        "df_sample['Product_Attributes'] = df_sample['Cleaned_Text'].apply(find_product_attributes)\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(df_sample[['Cleaned_Text', 'Product_Attributes']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42b16892",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "e5bf4187e6cf4a9697c18d65a9a343c3",
            "070b211282634a02a749eaf6b836cda9",
            "361d828156c04cb986632ee6fbdd4fde",
            "42e85d26002749849d66425943a5224c",
            "0c8f1e77b7334f67b41fccc9d1d9473d",
            "0f67d629b2a546288f485f64537cd467"
          ]
        },
        "id": "42b16892",
        "outputId": "c8eaebe1-aa16-4c9d-a179-4c2c0677a1d3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5bf4187e6cf4a9697c18d65a9a343c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "070b211282634a02a749eaf6b836cda9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "361d828156c04cb986632ee6fbdd4fde",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42e85d26002749849d66425943a5224c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c8f1e77b7334f67b41fccc9d1d9473d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f67d629b2a546288f485f64537cd467",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                             Cleaned_Text NER_Entities\n",
            "165256  having try couple brand gluten free sandwich c...           []\n",
            "231465  cat love treat find house pop bolt hide come t...           []\n",
            "427827  little expect   tend muddy taste expect say fa...           []\n",
            "433954  frosted mini wheat original size frosted mini ...           []\n",
            "70260   want congratulate graphic artist put entire pr...           []\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Cargar pipeline de NER de HuggingFace\n",
        "ner_pipeline = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
        "\n",
        "# Función para aplicar NER\n",
        "def apply_ner(text):\n",
        "    ner_results = ner_pipeline(text)\n",
        "    return [(result['word'], result['entity']) for result in ner_results]\n",
        "\n",
        "# Aplicar la función NER a la columna 'Cleaned_Text'\n",
        "df_sample['NER_Entities'] = df_sample['Cleaned_Text'].apply(apply_ner)\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(df_sample[['Cleaned_Text', 'NER_Entities']].head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6340afc2",
      "metadata": {
        "id": "6340afc2"
      },
      "source": [
        "**OBJETIVO 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Realizar fine-tuning para clasificación sobre un corpus y modelo LLM pre-entrenado de la plataforma HuggingFace**"
      ],
      "metadata": {
        "id": "tWLDqqXYHFAc"
      },
      "id": "tWLDqqXYHFAc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "instalamos dependencias"
      ],
      "metadata": {
        "id": "TEHFjA2KORuo"
      },
      "id": "TEHFjA2KORuo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbqD9jb18Mkr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "782c5d17-f9df-4246-af1b-068d75e72005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2024.6.2)\n",
            "Collecting transformers==4.40.2\n",
            "  Downloading transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.19.2-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.2) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.2) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.2) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.2) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.2) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.2) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.2) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.2) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.2) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.2) (4.66.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting requests (from transformers==4.40.2)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.2) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.2) (2024.6.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: xxhash, requests, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, transformers, datasets, accelerate\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.2\n",
            "    Uninstalling transformers-4.41.2:\n",
            "      Successfully uninstalled transformers-4.41.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.31.0 datasets-2.19.2 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 requests-2.32.3 transformers-4.40.2 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install requests==2.31.0\n",
        "!pip install transformers==4.40.2 datasets accelerate\n"
      ],
      "id": "VbqD9jb18Mkr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importamos librerías necesarias**"
      ],
      "metadata": {
        "id": "yGT6o4PSHd0k"
      },
      "id": "yGT6o4PSHd0k"
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n"
      ],
      "metadata": {
        "id": "9-oT8SQ-8YRj"
      },
      "execution_count": null,
      "outputs": [],
      "id": "9-oT8SQ-8YRj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cargamos y dividimos el Dataset mteb/mtop_domain**"
      ],
      "metadata": {
        "id": "xOUKzu9rHvIl"
      },
      "id": "xOUKzu9rHvIl"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"mteb/mtop_domain\")\n",
        "\n",
        "train_dataset = dataset['train'].shuffle(seed=42).select(range(5000))  # Selecciona una muestra de 5000 para entrenamiento\n",
        "test_dataset = dataset['validation'].shuffle(seed=42).select(range(1000))  # Selecciona una muestra de 1000 para validación\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362,
          "referenced_widgets": [
            "094dab1de23946ca9594347f01c023d7",
            "8d2c666b696748d393897021ee57e8e0",
            "a8469b53494440f58b4aab45eb1b3286",
            "c6b1b19808d74301bdea839bdd2c15ed",
            "96b2734b32084597bb9f38b2f4b33537",
            "ff603423aafe4ac8b178554d4fa83c18",
            "fcbdfe9c23f24cd8a7c5da9b3b0dd881",
            "2de5d379c59d4d7b8c0e9b5068e61f24",
            "dcbac8e5f28e47eeb0063d9335afa78e",
            "58b22a04c95b4f648d417ebbeb67cd71",
            "a175a0eafe7b4333b85b5ada120822a5",
            "d48dc1a50d7e467b82be01a46c56a5ea",
            "7ae5989e3a654c509664171a71c8400d",
            "7153f80ba2064b85becf73b2d1694513",
            "462012880ff74c5e897256c74509fb9b",
            "3655ff19cfbe4bce9bb5d1d027bd389b",
            "94b9ff7c099d44d5b05afccd3f98449b",
            "c111040575a44822b108f6410f0d9bbb",
            "9877d0f801e348b8a81ab808ca01a893",
            "9b8a861ab6be4b129cc6b22f40bd23ed",
            "1d1819c0e0c047e98e02405a2fcb25b7",
            "9fb5eb098da34dc0b09d9d03b437b25f",
            "028e6eb44c264cb8a6939f1e4cf1a58d",
            "11b261a4cc3b4730938bfc557204f700",
            "03dd27ff3b13454d95e606861199118a",
            "b82c4406d33b4a70b8e4cc4cb1bb79eb",
            "0d64c7023dd2466bbf6ced8e95affe83",
            "4537048df11f4c249e652e5a92d5b3a3",
            "3161110a77cc40b09501c25b07cd4822",
            "8fb1477f25184afa9e92c49114774131",
            "ffd091792ed848a0bbfca64ffbe3c7ff",
            "3693999ef49f425d80021acaaed5a81f",
            "cefa22be3b344c2a80ac097ef4e8254e",
            "9b14019c540d4eaaad0f7f02f647d5a8",
            "bcb72e18e7df4f39bdd5b4d9cf2e7028",
            "3021d11476be4cd6bac067a4f278c13e",
            "3407627e3f5843de96c38def4fa763be",
            "389ab22c46dc443c9e639f485d48e30d",
            "9a721b9a0a254f03bb33ecce50448310",
            "9aee18607eae45d8b76ef2044ba868cc",
            "80b3a4607dc54ec8bd7ccdc0612a8397",
            "ee82aceefae247278cebae75af4bca36",
            "ad185c64f4374846b56e38b8ec0af4a0",
            "aecdbfc7c6354659b3432ada526b7fbe",
            "cede61dd32b54a38ab773b1504f35004",
            "36f1b571317644648e7a4d4242ebefa2",
            "60c957d4fbf64c778bb874a9c84bd115",
            "12dfe1a56e744507b76700d799c1b0b0",
            "4527755d96794dcf8d7ab91f9d50a443",
            "de95750e09e84b558117e1f2cffd8cc0",
            "3b3bc0f78ca24f879b877e05be1a6ddf",
            "21246226710e4ad18f5799010045b331",
            "841ac021e4da48cba69d6075746b6400",
            "a4329e4a7255421396dd0e2cd9f9a1da",
            "86b1064f4f184d85823b0cfdcd50d291",
            "c40e494f98f04198aa9ba52b9e530710",
            "0df317f9176141feb22de526ee37a756",
            "08a1aba7579740659c1c5d284cd6f47d",
            "5e34d082534b488fb4712f38ffbb902d",
            "2a13361e6b8443f0a23d5a65e4680714",
            "fbddb23fc209418c98901f80cda00311",
            "9ebe0d36c8e8479ba0f1d5a7b8fc0b55",
            "887f53b41c914eeda6ff57c71763bbdf",
            "28c450d745004bc8998093d781fa7e5c",
            "5b82a329f094464ab28cbaa54f9a30b7",
            "1f41a2fc464f4bf9909c18cbb5f14ce0",
            "ea5ae88661334eec87961dfc76c8f494",
            "2cee3fe81fc04c1da67c9656ab2d63ea",
            "ae544c7cb5094abab464b1346dc8e1d7",
            "58abb178cd2d435f93cce72645ab5e8d",
            "990c85beb1a74b9c892c37d0314892c9",
            "57f3472e0bbf44c482f774c69283ff73",
            "4bd9640d28934159aeb8e2dc0b02f19c",
            "26accba222a145e8858072e25003349e",
            "9f30d0e5819e4c08bbc50b2b8c54bf89",
            "3f16ea6edf2c4ea7aee864a1dc33ce74",
            "9ef8ce8303ba4cfea9d583017b865811",
            "57c6dbed83ff4774803605e6274bfeef",
            "ee5ed72ab16340039e2296b6776740c6",
            "db2734e8c3d24522b115bdbad2ce4ac7",
            "8267f0d837db452c9b0f1e9b8caee886",
            "1368bdfd61884f3b8df1794ec8294ce7",
            "c781ea8b88d14a61901dc3a06d1db7bf",
            "7351034d93994be8ae77ff93f1518d91",
            "461cedbb63be4feb94475882eb26561c",
            "10880474cb95466d8d237ecef35f74d2",
            "c030e3e5b0b24161b002554141da57ea",
            "b4c9b5b8c6b44023bc1fe78d3cf63600"
          ]
        },
        "id": "vPgrV5st_ZaN",
        "outputId": "7945eac9-5304-42de-9379-84d45cdfec8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1491: FutureWarning: The repository for mteb/mtop_domain contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/mtop_domain\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "094dab1de23946ca9594347f01c023d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/86.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d48dc1a50d7e467b82be01a46c56a5ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.61M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "028e6eb44c264cb8a6939f1e4cf1a58d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/451k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b14019c540d4eaaad0f7f02f647d5a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/229k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cede61dd32b54a38ab773b1504f35004"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c40e494f98f04198aa9ba52b9e530710"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea5ae88661334eec87961dfc76c8f494"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57c6dbed83ff4774803605e6274bfeef"
            }
          },
          "metadata": {}
        }
      ],
      "id": "vPgrV5st_ZaN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cargamos el Tokenizer y el modelo precargado**"
      ],
      "metadata": {
        "id": "uW4gfFW6ICir"
      },
      "id": "uW4gfFW6ICir"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=11)  # Ajustar el número de etiquetas según el dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBvV3mEn_Zc8",
        "outputId": "e313b62a-bc18-4cce-e3a1-ca57171c5479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "id": "tBvV3mEn_Zc8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Procesamos los datos**"
      ],
      "metadata": {
        "id": "6jvn5_g8IQ1Z"
      },
      "id": "6jvn5_g8IQ1Z"
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "2f91b4b225c14fb4922fd7a9716bb962",
            "14478e9dfa3c4b72ac61e18b9dd2d508",
            "c905b7247eb74ab98a52fcb8c18c7d61",
            "cfd866a939ac47fdaa45b41010e338b6",
            "0207ec7c359b4517b6081bcd4abf15d5",
            "1b284fa30f544b57a57a6fcaf53315c5",
            "10403dd667ef486b87298f35b7f1d1e7",
            "82aba221b0704fac90ecac77adf6e3f8",
            "dd808152c9fa4d2d99acb1bec97c0937",
            "8fe7c67241ab472a93369d64d568efba",
            "0471e67663074d8b93012faa04ffa03f",
            "5b29f1d051d546078bb7f0c2ea126cb3",
            "460aeca70e85415980469ad0158ec30c",
            "cca2b36bde6c4ad2a1d9f0e6fe64e503",
            "af9d970157d247cf88c0f0768283575f",
            "9ad455682d96459b927775dcf2bd6cd5",
            "4e27594de10b4e0b8a34a7073c5d7fcc",
            "7ea6d464a5c144b9aab2cf103779f12e",
            "a61febff6a054971b57e4cfbf99a0788",
            "c2fba5f2c8104e8395e28dc6e61cafea",
            "c9e69462179b4327badc92b9ff00ca2c",
            "138d5c11477e432b96876d9da57ddec4"
          ]
        },
        "id": "sHwXEGCZ_ZfD",
        "outputId": "4a62e66c-cbc3-46e0-a7c3-9c83c09ff7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f91b4b225c14fb4922fd7a9716bb962"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b29f1d051d546078bb7f0c2ea126cb3"
            }
          },
          "metadata": {}
        }
      ],
      "id": "sHwXEGCZ_ZfD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**configuramos los argumentos de entrenamiento**"
      ],
      "metadata": {
        "id": "wutGmsYtIb9J"
      },
      "id": "wutGmsYtIb9J"
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n"
      ],
      "metadata": {
        "id": "0tLPOHq6_4x6"
      },
      "execution_count": null,
      "outputs": [],
      "id": "0tLPOHq6_4x6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entrenamos y evaluamos el modelo**"
      ],
      "metadata": {
        "id": "S7gsjgK1Il6D"
      },
      "id": "S7gsjgK1Il6D"
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "results = trainer.evaluate()\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "0PjF8ETx_74c",
        "outputId": "8e2aaf7a-a2ad-48d9-a143-d4021e0a0367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='939' max='939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [939/939 12:23, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.110384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.516500</td>\n",
              "      <td>0.069268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.516500</td>\n",
              "      <td>0.063906</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:16]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.06390639394521713, 'eval_runtime': 16.9562, 'eval_samples_per_second': 58.975, 'eval_steps_per_second': 3.715, 'epoch': 3.0}\n"
          ]
        }
      ],
      "id": "0PjF8ETx_74c"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}